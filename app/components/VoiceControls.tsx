'use client'

import { useState, useRef, useEffect } from 'react'
import VoiceOrb from './VoiceOrb'
import { AVAILABLE_TOOLS, TOOL_HANDLERS } from '../config/tools'
import { buildFinalSystemPrompt } from '../config/protected-prompt'

interface VoiceControlsProps {
  systemPrompt: string
  onVoiceStateChange: (state: 'disconnected' | 'connecting' | 'talking') => void
  onVolumeChange: (volume: number, type: 'input' | 'output') => void
  voiceState: 'disconnected' | 'connecting' | 'talking'
  inputVolume: number
  outputVolume: number
}

export default function VoiceControls({ systemPrompt, onVoiceStateChange, onVolumeChange, voiceState, inputVolume, outputVolume }: VoiceControlsProps) {
  const [isConnected, setIsConnected] = useState(false)
  const [isConnecting, setIsConnecting] = useState(false)
  const [isMuted, setIsMuted] = useState(false)
  
  const peerConnectionRef = useRef<RTCPeerConnection | null>(null)
  const dataChannelRef = useRef<RTCDataChannel | null>(null)
  const localStreamRef = useRef<MediaStream | null>(null)
  const remoteStreamRef = useRef<MediaStream | null>(null)
  const audioElementRef = useRef<HTMLAudioElement>(null)
  const audioContextRef = useRef<AudioContext | null>(null)
  const inputAnalyserRef = useRef<AnalyserNode | null>(null)
  const outputAnalyserRef = useRef<AnalyserNode | null>(null)
  const animationFrameRef = useRef<number | null>(null)
  const volumeHistoryRef = useRef<{ input: number[], output: number[] }>({ input: [], output: [] })
  const lastVolumeUpdateRef = useRef<number>(0)

  // –°–æ–∑–¥–∞–µ–º Audio —ç–ª–µ–º–µ–Ω—Ç –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è –æ—Ç–≤–µ—Ç–æ–≤ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞
  useEffect(() => {
    audioElementRef.current = new Audio()
    audioElementRef.current.autoplay = true
    return () => {
      if (audioElementRef.current) {
        audioElementRef.current.pause()
        audioElementRef.current = null
      }
      if (animationFrameRef.current) {
        cancelAnimationFrame(animationFrameRef.current)
      }
      if (audioContextRef.current) {
        audioContextRef.current.close()
      }
    }
  }, [])

  // –§—É–Ω–∫—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞ –≥—Ä–æ–º–∫–æ—Å—Ç–∏ —Å —à—É–º–æ–ø–æ–¥–∞–≤–ª–µ–Ω–∏–µ–º
  const analyzeAudio = () => {
    if (!inputAnalyserRef.current && !outputAnalyserRef.current) {
      return
    }

    const now = performance.now()
    
    // Throttling: –æ–±–Ω–æ–≤–ª—è–µ–º –Ω–µ —á–∞—â–µ 30 FPS –¥–ª—è –ø–ª–∞–≤–Ω–æ—Å—Ç–∏
    if (now - lastVolumeUpdateRef.current < 33) {
      animationFrameRef.current = requestAnimationFrame(analyzeAudio)
      return
    }
    lastVolumeUpdateRef.current = now

    // –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã –¥–ª—è —à—É–º–æ–ø–æ–¥–∞–≤–ª–µ–Ω–∏—è –∏ —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏—è
    const NOISE_GATE = 0.15  // –ü–æ—Ä–æ–≥ —à—É–º–∞ (15%)
    const SMOOTHING_FACTOR = 0.5  // –£–º–µ—Ä–µ–Ω–Ω–æ–µ —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ
    const HISTORY_SIZE = 5  // –†–∞–∑–º–µ—Ä –æ–∫–Ω–∞ —É—Å—Ä–µ–¥–Ω–µ–Ω–∏—è

    // –ê–Ω–∞–ª–∏–∑ –≤—Ö–æ–¥—è—â–µ–≥–æ –∑–≤—É–∫–∞ (–º–∏–∫—Ä–æ—Ñ–æ–Ω)
    if (inputAnalyserRef.current) {
      const bufferLength = inputAnalyserRef.current.frequencyBinCount
      const dataArray = new Uint8Array(bufferLength)
      inputAnalyserRef.current.getByteFrequencyData(dataArray)
      
      // –í—ã—á–∏—Å–ª—è–µ–º RMS (Root Mean Square) –¥–ª—è –±–æ–ª–µ–µ —Ç–æ—á–Ω–æ–π –≥—Ä–æ–º–∫–æ—Å—Ç–∏
      const rms = Math.sqrt(dataArray.reduce((sum, value) => sum + value * value, 0) / bufferLength)
      let volume = Math.min(rms / 128, 1)
      
      // –ü—Ä–∏–º–µ–Ω—è–µ–º noise gate - –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º —Ç–∏—Ö–∏–µ –∑–≤—É–∫–∏
      if (volume < NOISE_GATE) {
        volume = 0
      } else {
        // –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –ø–æ—Ä–æ–≥–∞ —à—É–º–∞
        volume = (volume - NOISE_GATE) / (1 - NOISE_GATE)
      }
      
      // –î–æ–±–∞–≤–ª—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é –¥–ª—è —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏—è
      volumeHistoryRef.current.input.push(volume)
      if (volumeHistoryRef.current.input.length > HISTORY_SIZE) {
        volumeHistoryRef.current.input.shift()
      }
      
      // –í—ã—á–∏—Å–ª—è–µ–º —Å–≥–ª–∞–∂–µ–Ω–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
      const smoothedVolume = volumeHistoryRef.current.input.reduce((sum, v) => sum + v, 0) / volumeHistoryRef.current.input.length
      
      // –ü—Ä–∏–º–µ–Ω—è–µ–º —ç–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–µ —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ
      const finalVolume = smoothedVolume * SMOOTHING_FACTOR + (volumeHistoryRef.current.input[volumeHistoryRef.current.input.length - 1] || 0) * (1 - SMOOTHING_FACTOR)
      
      // –î–µ–±–∞–≥ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è (—Ç–æ–ª—å–∫–æ –ø—Ä–∏ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã—Ö –∏–∑–º–µ–Ω–µ–Ω–∏—è—Ö)
      if (Math.abs(finalVolume - (volumeHistoryRef.current.input[volumeHistoryRef.current.input.length - 2] || 0)) > 0.1) {
        console.log(`üé§ Input volume: ${(finalVolume * 100).toFixed(1)}%`);
      }
      
      onVolumeChange(finalVolume, 'input')
    }

    // –ê–Ω–∞–ª–∏–∑ –∏—Å—Ö–æ–¥—è—â–µ–≥–æ –∑–≤—É–∫–∞ (–æ—Ç–≤–µ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞)  
    if (outputAnalyserRef.current) {
      const bufferLength = outputAnalyserRef.current.frequencyBinCount
      const dataArray = new Uint8Array(bufferLength)
      outputAnalyserRef.current.getByteFrequencyData(dataArray)
      
      // –ê–Ω–∞–ª–æ–≥–∏—á–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è –≤—ã—Ö–æ–¥–Ω–æ–≥–æ –∑–≤—É–∫–∞
      const rms = Math.sqrt(dataArray.reduce((sum, value) => sum + value * value, 0) / bufferLength)
      let volume = Math.min(rms / 128, 1)
      
      // –û–¢–õ–ê–î–ö–ê: –≤—Å–µ–≥–¥–∞ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º raw –¥–∞–Ω–Ω—ã–µ –¥–ª—è output
      if (rms > 5) {
        // –¢–∏—Ö–∏–π –∞–Ω–∞–ª–∏–∑ –≥—Ä–æ–º–∫–æ—Å—Ç–∏ output
      }
      
      // –î–ª—è —Ä–µ—á–∏ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–æ–ª–µ–µ –Ω–∏–∑–∫–∏–π –ø–æ—Ä–æ–≥
      const OUTPUT_NOISE_GATE = 0.08
      if (volume < OUTPUT_NOISE_GATE) {
        volume = 0
      } else {
        volume = (volume - OUTPUT_NOISE_GATE) / (1 - OUTPUT_NOISE_GATE)
      }
      
      volumeHistoryRef.current.output.push(volume)
      if (volumeHistoryRef.current.output.length > HISTORY_SIZE) {
        volumeHistoryRef.current.output.shift()
      }
      
      const smoothedVolume = volumeHistoryRef.current.output.reduce((sum, v) => sum + v, 0) / volumeHistoryRef.current.output.length
      const finalVolume = smoothedVolume * SMOOTHING_FACTOR + (volumeHistoryRef.current.output[volumeHistoryRef.current.output.length - 1] || 0) * (1 - SMOOTHING_FACTOR)
      
      // –î–µ–±–∞–≥ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –¥–ª—è –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Å–∏–≥–Ω–∞–ª–∞ - –í–°–ï–ì–î–ê –ø–æ–∫–∞–∑—ã–≤–∞–µ–º
      if (finalVolume > 0.05) {
        // –¢–∏—Ö–∏–π –∞–Ω–∞–ª–∏–∑ - –ª–æ–≥ —É–±—Ä–∞–Ω
      }
      
      // –£–±—Ä–∞–ª–∏ –ª–æ–≥–∏–∫—É –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏–π - –æ—Å—Ç–∞–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ talking
      
      onVolumeChange(finalVolume, 'output')
    }

    animationFrameRef.current = requestAnimationFrame(analyzeAudio)
  }

  const connectToRealtimeAPI = async () => {
    if (isConnecting || isConnected) return;
    
    setIsConnecting(true);
    onVoiceStateChange('connecting');

    try {
      // –ü–æ–ª—É—á–∞–µ–º ephemeral token
      const response = await fetch('/api/session', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({ systemPrompt }),
      });

      if (!response.ok) {
        throw new Error(`HTTP error! status: ${response.status}`);
      }

      const tokenData = await response.json();
      console.log('Token response:', tokenData);
      
      const token = tokenData.client_secret?.value || tokenData.client_secret || tokenData.token || tokenData.access_token;
      
      if (!token) {
        console.error('Token structure:', tokenData);
        throw new Error('No token found in response');
      }

      // –°–æ–∑–¥–∞–µ–º WebRTC —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ
      const pc = new RTCPeerConnection();
      
      // –î–æ–±–∞–≤–ª—è–µ–º –∞—É–¥–∏–æ —Ç—Ä–µ–∫
      const ms = await navigator.mediaDevices.getUserMedia({ 
        audio: { 
          echoCancellation: true, 
          noiseSuppression: true,
          sampleRate: 24000 
        } 
      });
      pc.addTrack(ms.getTracks()[0], ms);

      // –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –∞–Ω–∞–ª–∏–∑ –≤—Ö–æ–¥—è—â–µ–≥–æ –∞—É–¥–∏–æ (–º–∏–∫—Ä–æ—Ñ–æ–Ω)
      audioContextRef.current = new AudioContext();
      const source = audioContextRef.current.createMediaStreamSource(ms);
      inputAnalyserRef.current = audioContextRef.current.createAnalyser();
      
      // –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ä–µ—á–∏
      inputAnalyserRef.current.fftSize = 512;  // –ë–æ–ª—å—à–µ —Ç–æ—á–Ω–æ—Å—Ç–∏
      inputAnalyserRef.current.smoothingTimeConstant = 0.3;  // –°–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ
      inputAnalyserRef.current.minDecibels = -90;
      inputAnalyserRef.current.maxDecibels = -10;
      
      source.connect(inputAnalyserRef.current);

      // –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Ö–æ–¥—è—â–∏—Ö –∞—É–¥–∏–æ
      pc.ontrack = e => {
        remoteStreamRef.current = e.streams[0];
        console.log('üîä –ü–æ–ª—É—á–µ–Ω remote stream –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞:', e.streams[0]);
        
        if (audioElementRef.current) {
          audioElementRef.current.srcObject = e.streams[0];
          
                    // –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –∞–Ω–∞–ª–∏–∑ –∏—Å—Ö–æ–¥—è—â–µ–≥–æ –∞—É–¥–∏–æ –°–†–ê–ó–£ —á–µ—Ä–µ–∑ MediaStream
          if (audioContextRef.current) {
            try {
              const outputSource = audioContextRef.current.createMediaStreamSource(e.streams[0]);
              outputAnalyserRef.current = audioContextRef.current.createAnalyser();
              
              // –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ä–µ—á–∏ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞
              outputAnalyserRef.current.fftSize = 512;
              outputAnalyserRef.current.smoothingTimeConstant = 0.4;
              outputAnalyserRef.current.minDecibels = -90;
              outputAnalyserRef.current.maxDecibels = -10;
              
              outputSource.connect(outputAnalyserRef.current);
              
              console.log('üîä Output –∞–Ω–∞–ª–∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–Ω —á–µ—Ä–µ–∑ MediaStream');
            } catch (error) {
              console.error('üîä –û—à–∏–±–∫–∞ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ output –∞–Ω–∞–ª–∏–∑–∞:', error);
            }
          }
        }
      };

      // –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º DataChannel listeners –ü–ï–†–ï–î offer/answer –ø—Ä–æ—Ü–µ—Å—Å–æ–º
      console.log('üîÑ –û–∂–∏–¥–∞–µ–º DataChannel –æ—Ç OpenAI...');
      pc.addEventListener('datachannel', (event) => {
        const dataChannel = event.channel;
        dataChannelRef.current = dataChannel;
        console.log('üì° ‚úÖ DataChannel –ø–æ–ª—É—á–µ–Ω –æ—Ç OpenAI:', dataChannel.label, dataChannel.readyState);

        dataChannel.addEventListener('message', (event) => {
          try {
            const realtimeEvent = JSON.parse(event.data);
            console.log('üì° üéØ VAD –°–û–ë–´–¢–ò–ï –æ—Ç OpenAI:', realtimeEvent.type, realtimeEvent);
            handleRealtimeEvent(realtimeEvent);
            // –¢–∏—Ö–∞—è —Ä–∞–±–æ—Ç–∞ - –æ—Ç–ª–∞–¥–æ—á–Ω—ã–µ –ª–æ–≥–∏ —É–±—Ä–∞–Ω—ã
          } catch (error) {
            console.error('‚ùå Error parsing realtime event:', error, event.data);
          }
        });

        dataChannel.addEventListener('open', () => {
          console.log('‚úÖ DataChannel –æ—Ç–∫—Ä—ã—Ç - –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ VAD');
          
          // –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –Ω–∞—á–∞–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ —Å–µ—Å—Å–∏–∏ —Å VAD –∏ Tools
          const finalPrompt = buildFinalSystemPrompt(systemPrompt);
          const sessionUpdate = {
            type: 'session.update',
            session: {
              instructions: finalPrompt,
              voice: 'alloy',
              input_audio_format: 'pcm16',
              output_audio_format: 'pcm16',
              turn_detection: {
                type: 'server_vad',
                threshold: 0.5,
                prefix_padding_ms: 300,
                silence_duration_ms: 200
              },
              tools: AVAILABLE_TOOLS
            }
          };
          
          console.log('üì° –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ VAD:', sessionUpdate);
          
          try {
            dataChannel.send(JSON.stringify(sessionUpdate));
            console.log('‚úÖ –ù–∞—Å—Ç—Ä–æ–π–∫–∏ VAD –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ');
          } catch (error) {
            console.error('‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –Ω–∞—Å—Ç—Ä–æ–µ–∫ VAD:', error);
          }
        });

        dataChannel.addEventListener('error', (error) => {
          console.error('‚ùå DataChannel error:', error);
        });

        dataChannel.addEventListener('close', () => {
          console.log('üì° DataChannel –∑–∞–∫—Ä—ã—Ç');
        });
      });

      // –°–æ–∑–¥–∞–µ–º offer
      const offer = await pc.createOffer();
      await pc.setLocalDescription(offer);

      // –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ OpenAI Realtime API (–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π URL!)
      const sdpResponse = await fetch('https://api.openai.com/v1/realtime?model=gpt-4o-realtime-preview-2024-12-17', {
        method: 'POST',
        body: offer.sdp,
        headers: {
          Authorization: `Bearer ${token}`,
          'Content-Type': 'application/sdp'
        },
      });

      if (!sdpResponse.ok) {
        throw new Error('Failed to connect to OpenAI Realtime API');
      }

      const answerSdp = await sdpResponse.text();
      await pc.setRemoteDescription({
        type: 'answer',
        sdp: answerSdp,
      });

      peerConnectionRef.current = pc;
      localStreamRef.current = ms;
      setIsConnected(true);
      onVoiceStateChange('talking');

      // –ó–∞–ø—É—Å–∫–∞–µ–º –∞–Ω–∞–ª–∏–∑ –≥—Ä–æ–º–∫–æ—Å—Ç–∏
      analyzeAudio();

      // –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ç—É—Å DataChannel —á–µ—Ä–µ–∑ 3 —Å–µ–∫—É–Ω–¥—ã
      setTimeout(() => {
        const channelStatus = dataChannelRef.current?.readyState || 'not_created';
        console.log('üîç DataChannel —Å—Ç–∞—Ç—É—Å —á–µ—Ä–µ–∑ 3 —Å–µ–∫:', channelStatus);
        if (channelStatus !== 'open') {
          console.log('‚ö†Ô∏è DataChannel –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç, –∏—Å–ø–æ–ª—å–∑—É–µ–º FALLBACK –Ω–∞ –∞–Ω–∞–ª–∏–∑ –≥—Ä–æ–º–∫–æ—Å—Ç–∏');
        }
      }, 3000);

      console.log('Successfully connected to OpenAI Realtime API');
    } catch (error) {
      console.error('Error connecting to Realtime API:', error);
      alert('–û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ API. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∫–æ–Ω—Å–æ–ª—å –¥–ª—è –¥–µ—Ç–∞–ª–µ–π.');
      setIsConnecting(false);
      onVoiceStateChange('disconnected');
    }
  };

  // –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—ã–∑–æ–≤–æ–≤ —Ñ—É–Ω–∫—Ü–∏–π (tools)
  const handleToolCall = async (event: { name: string; call_id: string; arguments: string }) => {
    const { name, call_id, arguments: args } = event;
    console.log('üîß Tool call:', name, 'with args:', args);
    
    try {
      // –ù–∞—Ö–æ–¥–∏–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ —Ñ—É–Ω–∫—Ü–∏–∏
      const handler = TOOL_HANDLERS[name as keyof typeof TOOL_HANDLERS];
      if (!handler) {
        throw new Error(`Unknown tool: ${name}`);
      }
      
      // –í—ã–ø–æ–ª–Ω—è–µ–º —Ñ—É–Ω–∫—Ü–∏—é
      const result = await handler(JSON.parse(args));
      console.log('üîß Tool result:', result);
      
      // –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –æ–±—Ä–∞—Ç–Ω–æ –≤ OpenAI
      if (dataChannelRef.current && dataChannelRef.current.readyState === 'open') {
        const toolResponse = {
          type: 'conversation.item.create',
          item: {
            type: 'function_call_output',
            call_id: call_id,
            output: JSON.stringify(result)
          }
        };
        
        dataChannelRef.current.send(JSON.stringify(toolResponse));
        console.log('üîß Tool response sent:', toolResponse);
        
        // –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –Ω–æ–≤—ã–π –æ—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏
        const createResponse = {
          type: 'response.create'
        };
        dataChannelRef.current.send(JSON.stringify(createResponse));
        console.log('üîß Requested new response from model');
      }
    } catch (error) {
      console.error('üîß Tool execution error:', error);
      
      // –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ—à–∏–±–∫—É –æ–±—Ä–∞—Ç–Ω–æ –≤ OpenAI
      if (dataChannelRef.current && dataChannelRef.current.readyState === 'open') {
        const errorResponse = {
          type: 'conversation.item.create',
          item: {
            type: 'function_call_output',
            call_id: call_id,
            output: JSON.stringify({
              success: false,
              error: error instanceof Error ? error.message : 'Unknown error'
            })
          }
        };
        
        dataChannelRef.current.send(JSON.stringify(errorResponse));
        console.log('üîß Tool error response sent:', errorResponse);
      }
    }
  };

  const handleRealtimeEvent = (event: { type: string; [key: string]: unknown }) => {
    console.log('üé™ handleRealtimeEvent –í–´–ó–í–ê–ù:', event.type);
    switch (event.type) {
      case 'session.created':
        console.log('üîÑ –°–µ—Å—Å–∏—è —Å–æ–∑–¥–∞–Ω–∞:', event.session);
        break;
        
      case 'conversation.item.created':
        console.log('üí¨ –≠–ª–µ–º–µ–Ω—Ç –±–µ—Å–µ–¥—ã —Å–æ–∑–¥–∞–Ω:', event.item);
        break;
        
      case 'response.created':
        console.log('üéØ –û—Ç–≤–µ—Ç —Å–æ–∑–¥–∞–Ω:', event.response);
        break;
        
      case 'response.output_item.added':
        console.log('üì§ –í—ã—Ö–æ–¥–Ω–æ–π —ç–ª–µ–º–µ–Ω—Ç –¥–æ–±–∞–≤–ª–µ–Ω:', event.item);
        break;
        
      case 'response.audio.delta':
        console.log('üéµ VAD: –ò–ò –Ω–∞—á–∞–ª –≥–æ–≤–æ—Ä–∏—Ç—å - –∞—É–¥–∏–æ –¥–µ–ª—å—Ç–∞');
        break;
        
      case 'response.audio.done':
        console.log('üéµ VAD: –ò–ò –∑–∞–∫–æ–Ω—á–∏–ª –≥–æ–≤–æ—Ä–∏—Ç—å - –∞—É–¥–∏–æ –∑–∞–≤–µ—Ä—à–µ–Ω–æ');
        break;
        
      case 'input_audio_buffer.speech_started':
        console.log('üé§ VAD: –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–∞—á–∞–ª –≥–æ–≤–æ—Ä–∏—Ç—å');
        break;
        
      case 'input_audio_buffer.speech_stopped':
        console.log('üé§ VAD: –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –∑–∞–∫–æ–Ω—á–∏–ª –≥–æ–≤–æ—Ä–∏—Ç—å');
        break;
        
      case 'response.done':
        console.log('üèÅ VAD: –û—Ç–≤–µ—Ç –∑–∞–≤–µ—Ä—à–µ–Ω:', event.response);
        break;
        
      // === –û–ë–†–ê–ë–û–¢–ö–ê FUNCTION CALLS ===
      case 'response.function_call_arguments.delta':
        console.log('üîß Tool call arguments delta:', event);
        break;
        
      case 'response.function_call_arguments.done':
        console.log('üîß Tool call arguments ready:', event);
        handleToolCall(event as unknown as { name: string; call_id: string; arguments: string });
        break;
        
      default:
        console.log('üì® –ù–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–µ —Å–æ–±—ã—Ç–∏–µ:', event.type);
        break;
    }
  };

  const disconnect = () => {
    // –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∞–Ω–∞–ª–∏–∑ –∞—É–¥–∏–æ
    if (animationFrameRef.current) {
      cancelAnimationFrame(animationFrameRef.current);
      animationFrameRef.current = null;
    }
    if (audioContextRef.current) {
      audioContextRef.current.close();
      audioContextRef.current = null;
    }
    
    if (peerConnectionRef.current) {
      peerConnectionRef.current.close();
      peerConnectionRef.current = null;
    }
    if (localStreamRef.current) {
      localStreamRef.current.getTracks().forEach((track: MediaStreamTrack) => track.stop());
      localStreamRef.current = null;
    }
    if (dataChannelRef.current) {
      dataChannelRef.current = null;
    }
    
    inputAnalyserRef.current = null;
    outputAnalyserRef.current = null;
    
    // –°–±—Ä–∞—Å—ã–≤–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é –≥—Ä–æ–º–∫–æ—Å—Ç–∏
    volumeHistoryRef.current = { input: [], output: [] };
    lastVolumeUpdateRef.current = 0;
    
    // –°–±—Ä–∞—Å—ã–≤–∞–µ–º –í–°–ï —Å–æ—Å—Ç–æ—è–Ω–∏—è –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è
    setIsConnected(false);
    setIsConnecting(false);
    onVoiceStateChange('disconnected');
    onVolumeChange(0, 'input');
    onVolumeChange(0, 'output');
  };

  const toggleMute = () => {
    if (audioElementRef.current) {
      audioElementRef.current.muted = !isMuted;
      setIsMuted(!isMuted);
    }
  };

  return (
    <div className="space-y-10">
      {/* Welcome –∑–∞–≥–æ–ª–æ–≤–æ–∫ */}
      <div className="text-center max-w-md mx-auto animate-fade-in-up">
        <h2 className="heading-secondary mb-4">–ò–ò –ì–æ–ª–æ—Å–æ–≤–æ–π –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç</h2>
        <p className="text-body mb-8">
          –ù–∞–∂–º–∏—Ç–µ –∫–Ω–æ–ø–∫—É&nbsp;&ldquo;–ù–∞—á–∞—Ç—å&nbsp;—Ä–∞–∑–≥–æ–≤–æ—Ä&rdquo; –∏&nbsp;–æ–±—â–∞–π—Ç–µ—Å—å<br />
          —Å&nbsp;–ò–ò-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–æ–º –≥–æ–ª–æ—Å–æ–º.
        </p>
      </div>

      {/* VoiceOrb - —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã–π —ç–ª–µ–º–µ–Ω—Ç */}
      <div className="flex justify-center mb-12">
        <VoiceOrb 
          state={voiceState}
          inputVolume={inputVolume}
          outputVolume={outputVolume}
        />
      </div>

      {/* –ë–µ–ª–∞—è –∫–∞—Ä—Ç–æ—á–∫–∞ —Å –Ω–∏–∂–Ω–∏–º–∏ —ç–ª–µ–º–µ–Ω—Ç–∞–º–∏ */}
      <div className="max-w-2xl mx-auto px-4">
        <div className="card p-6 md:p-8 space-y-6 animate-fade-in-up inline-block w-full" style={{animationDelay: '0.2s'}}>
          {/* –°—Ç–∞—Ç—É—Å –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è */}
          <div className="text-center">
            <div className={`status-indicator ${
              isConnected 
                ? 'status-connected' 
                : isConnecting 
                ? 'status-connecting animate-pulse-soft'
                : 'status-disconnected'
            }`}>
              <div className={`w-2 h-2 rounded-full mr-3 ${
                isConnected 
                  ? 'bg-green-500' 
                  : isConnecting 
                  ? 'bg-yellow-500'
                  : 'bg-gray-500'
              }`} />
              {isConnected ? '–ü–æ–¥–∫–ª—é—á–µ–Ω' : isConnecting ? '–ü–æ–¥–∫–ª—é—á–∞–µ—Ç—Å—è...' : '–û—Ç–∫–ª—é—á–µ–Ω'}
            </div>
          </div>

          {/* –ì–æ–ª–æ—Å–æ–≤—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è */}
      <div className="flex items-center justify-center space-x-6">
        {!isConnected ? (
          <button
            onClick={connectToRealtimeAPI}
            disabled={isConnecting}
            className={`btn-primary ${isConnecting ? 'animate-pulse-soft' : ''}`}
          >
            <div className="flex items-center space-x-3">
              <svg className="w-6 h-6" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M19 11a7 7 0 01-7 7m0 0a7 7 0 01-7-7m7 7v4m0 0H8m4 0h4m-4-8a3 3 0 01-3-3V5a3 3 0 116 0v6a3 3 0 01-3 3z" />
              </svg>
              <span>{isConnecting ? '–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ...' : '–ù–∞—á–∞—Ç—å —Ä–∞–∑–≥–æ–≤–æ—Ä'}</span>
            </div>
          </button>
        ) : (
          <>
            <button
              onClick={disconnect}
              className="bg-gradient-to-r from-red-500 to-pink-600 hover:from-red-600 hover:to-pink-700 text-white font-semibold py-4 px-8 rounded-2xl transform transition-all duration-200 ease-in-out hover:scale-105 hover:shadow-lg focus:outline-none focus:ring-4 focus:ring-red-300 btn-disconnect"
            >
              <div className="flex items-center space-x-3">
                <svg className="w-5 h-5" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                  <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M6 18L18 6M6 6l12 12" />
                </svg>
                <span>–û—Ç–∫–ª—é—á–∏—Ç—å—Å—è</span>
              </div>
            </button>
            
            <button
              onClick={toggleMute}
              className={`glass p-4 rounded-2xl hover-lift transition-all duration-200 ${
                isMuted 
                  ? 'text-red-600 bg-red-50/50' 
                  : 'text-gray-600 hover:text-gray-800'
              }`}
              title={isMuted ? '–í–∫–ª—é—á–∏—Ç—å –∑–≤—É–∫' : '–í—ã–∫–ª—é—á–∏—Ç—å –∑–≤—É–∫'}
            >
              {isMuted ? (
                // –ò–∫–æ–Ω–∫–∞ "–∑–≤—É–∫ –≤—ã–∫–ª—é—á–µ–Ω" - –¥–∏–Ω–∞–º–∏–∫ –ø–µ—Ä–µ—á–µ—Ä–∫–Ω—É—Ç—ã–π
                <svg className="w-6 h-6" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                  <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M5.586 15H4a1 1 0 01-1-1v-4a1 1 0 011-1h1.586l4.707-4.707C10.923 3.663 12 4.109 12 5v14c0 .891-1.077 1.337-1.707.707L5.586 15z" />
                  <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M18 3L1 20" />
                </svg>
              ) : (
                // –ò–∫–æ–Ω–∫–∞ "–∑–≤—É–∫ –≤–∫–ª—é—á–µ–Ω" - –¥–∏–Ω–∞–º–∏–∫ —Å –≤–æ–ª–Ω–∞–º–∏ –∑–≤—É–∫–∞
                <svg className="w-6 h-6" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                  <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M5.586 15H4a1 1 0 01-1-1v-4a1 1 0 011-1h1.586l4.707-4.707C10.923 3.663 12 4.109 12 5v14c0 .891-1.077 1.337-1.707.707L5.586 15z" />
                  <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M15 9.5c.5.5 1 1.5 1 2.5s-.5 2-1 2.5" />
                  <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M18 7.5c1 1 2 2.5 2 4.5s-1 3.5-2 4.5" />
                </svg>
              )}
            </button>
          </>
        )}
      </div>

          {/* –ò–Ω–¥–∏–∫–∞—Ç–æ—Ä –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ */}
          {isConnected && (
            <div className="text-center">
              <div className="glass p-4 rounded-2xl max-w-xs mx-auto">
                <div className="flex items-center justify-center space-x-3">
                  <div className="w-3 h-3 rounded-full bg-green-500 animate-pulse-soft" />
                  <span className="text-sm font-medium text-green-800">
                    –†–∞–∑–≥–æ–≤–∞—Ä–∏–≤–∞–µ–º
                  </span>
                </div>
              </div>
            </div>
          )}
        </div>
      </div>
    </div>
  )
}